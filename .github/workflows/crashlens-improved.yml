name: CrashLens Analysis (Improved)

on:
  # Run on push to main and pull requests
  push:
    branches: [ main, raj ]
  pull_request:
    branches: [ main ]
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      scan_type:
        description: 'Type of scan to perform'
        required: true
        default: 'full'
        type: choice
        options:
          - full
          - policy-check
          - simulate-only
      
  # Run daily at 6 AM UTC
  schedule:
    - cron: '0 6 * * *'

jobs:
  crashlens-analysis:
    runs-on: ubuntu-latest
    name: CrashLens Token Waste Detection
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
          
      - name: Install CrashLens and Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          # Install the actual CrashLens package
          pip install crashlens>=2.9.1
          
      - name: Verify CrashLens Installation
        run: |
          echo "ðŸ” Verifying CrashLens installation..."
          crashlens --version
          crashlens list-policy-templates
          
      - name: Create Logs Directory
        run: |
          mkdir -p logs
          mkdir -p analysis-results
          
      - name: Generate Test Data (if no existing logs)
        run: |
          echo "ðŸ“Š Generating realistic test data for analysis..."
          
          # Generate realistic Langfuse-style traces for testing
          crashlens simulate \
            --output logs/simulated_traces.jsonl \
            --count 50 \
            --include-retries \
            --include-expensive-models \
            --include-token-waste \
            || echo "âš ï¸ Simulation command may not support all flags, continuing..."
          
          # Fallback: Create basic simulation
          if [ ! -f "logs/simulated_traces.jsonl" ]; then
            echo "Creating fallback test data..."
            crashlens simulate --output logs/simulated_traces.jsonl --count 20 || echo "Using existing logs"
          fi
          
      - name: List Available Policy Templates
        run: |
          echo "ðŸ“œ Available CrashLens policy templates:"
          crashlens list-policy-templates
          
      - name: Run CrashLens Policy Check
        id: policy-check
        run: |
          echo "ðŸ” Running CrashLens policy check..."
          
          # Run policy check on all available log files
          log_files=$(find logs/ -name "*.jsonl" -type f 2>/dev/null || echo "")
          
          if [ -n "$log_files" ]; then
            echo "Found log files: $log_files"
            
            # Run policy check with retry policy if it exists
            if [ -f "crashlens_retry_policy.yaml" ]; then
              echo "Using custom retry policy..."
              crashlens policy-check \
                --policy crashlens_retry_policy.yaml \
                --output analysis-results/policy-check-results.json \
                logs/*.jsonl \
                || echo "Policy check completed with violations"
            else
              echo "Using default policies..."
              crashlens policy-check \
                --output analysis-results/policy-check-results.json \
                logs/*.jsonl \
                || echo "Policy check completed with violations"
            fi
          else
            echo "No log files found, creating empty results"
            echo '{"message": "No log files found for analysis"}' > analysis-results/policy-check-results.json
          fi
          
      - name: Run CrashLens Full Scan
        if: github.event.inputs.scan_type == 'full' || github.event.inputs.scan_type == ''
        run: |
          echo "ðŸŽ¯ Running comprehensive CrashLens scan..."
          
          # Find log files
          log_files=$(find logs/ -name "*.jsonl" -type f 2>/dev/null || echo "")
          
          if [ -n "$log_files" ]; then
            # Run comprehensive scan
            crashlens scan \
              --config crashlens_config.yaml \
              --output analysis-results/scan-results.json \
              --format json \
              logs/*.jsonl \
              || echo "Scan completed with findings"
          else
            echo "No log files for scanning"
            echo '{"message": "No log files found for scanning"}' > analysis-results/scan-results.json
          fi
          
      - name: Analyze Results and Generate Report
        run: |
          echo "ðŸ“Š Analyzing CrashLens results..."
          
          # Create analysis script
          cat > analyze_results.py << 'EOF'
          import json
          import os
          from datetime import datetime
          
          def analyze_crashlens_results():
              print("=== CrashLens Analysis Report ===\n")
              
              results = {}
              
              # Load policy check results
              policy_file = "analysis-results/policy-check-results.json"
              if os.path.exists(policy_file):
                  try:
                      with open(policy_file, 'r') as f:
                          policy_results = json.load(f)
                      results['policy_check'] = policy_results
                      print(f"âœ… Policy check results loaded")
                  except Exception as e:
                      print(f"âš ï¸ Error loading policy results: {e}")
              
              # Load scan results
              scan_file = "analysis-results/scan-results.json"
              if os.path.exists(scan_file):
                  try:
                      with open(scan_file, 'r') as f:
                          scan_results = json.load(f)
                      results['scan'] = scan_results
                      print(f"âœ… Scan results loaded")
                  except Exception as e:
                      print(f"âš ï¸ Error loading scan results: {e}")
              
              # Generate summary
              summary = {
                  'timestamp': datetime.now().isoformat(),
                  'total_violations': 0,
                  'critical_violations': 0,
                  'high_violations': 0,
                  'medium_violations': 0,
                  'low_violations': 0,
                  'estimated_waste': 0.0,
                  'files_analyzed': []
              }
              
              # Count violations from policy check
              if 'policy_check' in results:
                  policy_data = results['policy_check']
                  if isinstance(policy_data, dict):
                      violations = policy_data.get('violations', [])
                      summary['total_violations'] = len(violations)
                      
                      for violation in violations:
                          severity = violation.get('severity', 'unknown').lower()
                          if severity == 'critical':
                              summary['critical_violations'] += 1
                          elif severity == 'high':
                              summary['high_violations'] += 1
                          elif severity == 'medium':
                              summary['medium_violations'] += 1
                          elif severity == 'low':
                              summary['low_violations'] += 1
              
              # Save summary
              with open('analysis-results/summary.json', 'w') as f:
                  json.dump(summary, f, indent=2)
              
              # Print summary
              print(f"\nðŸ“ˆ Analysis Summary:")
              print(f"   Total violations: {summary['total_violations']}")
              print(f"   Critical: {summary['critical_violations']}")
              print(f"   High: {summary['high_violations']}")
              print(f"   Medium: {summary['medium_violations']}")
              print(f"   Low: {summary['low_violations']}")
              
              return summary
          
          if __name__ == "__main__":
              analyze_crashlens_results()
          EOF
          
          python analyze_results.py
          
      - name: Generate Markdown Report
        run: |
          echo "ðŸ“„ Generating markdown report..."
          
          cat > analysis-results/crashlens-report.md << 'EOF'
          # CrashLens Analysis Report
          
          **Generated:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Repository:** ${{ github.repository }}
          **Branch:** ${{ github.ref_name }}
          **Commit:** ${{ github.sha }}
          **CrashLens Version:** $(crashlens --version | cut -d' ' -f3)
          
          ## Analysis Overview
          
          This report shows the results of CrashLens token waste detection analysis.
          
          ### Files Analyzed
          EOF
          
          # Add log file information
          find logs/ -name "*.jsonl" -type f 2>/dev/null | while read file; do
            echo "- \`$file\` ($(wc -l < "$file" 2>/dev/null || echo "0") lines)" >> analysis-results/crashlens-report.md
          done || echo "- No log files found" >> analysis-results/crashlens-report.md
          
          cat >> analysis-results/crashlens-report.md << 'EOF'
          
          ### Policy Templates Used
          EOF
          
          # Add policy information
          if [ -f "crashlens_retry_policy.yaml" ]; then
            echo "- Custom retry detection policy (\`crashlens_retry_policy.yaml\`)" >> analysis-results/crashlens-report.md
          else
            echo "- Default CrashLens policies" >> analysis-results/crashlens-report.md
          fi
          
          cat >> analysis-results/crashlens-report.md << 'EOF'
          
          ### Results Summary
          
          See the detailed results in the workflow artifacts:
          - `policy-check-results.json` - Policy violation details
          - `scan-results.json` - Comprehensive scan results  
          - `summary.json` - Analysis summary
          
          ## Recommendations
          
          1. **Review Violations**: Check the JSON results for specific token waste patterns
          2. **Implement Fixes**: Address high and critical severity violations first
          3. **Monitor Trends**: Set up regular CrashLens scans to track improvements
          4. **Optimize Prompts**: Use CrashLens suggestions to reduce token usage
          
          ---
          *Generated by CrashLens v$(crashlens --version | cut -d' ' -f3)*
          EOF
          
      - name: Check for Critical Violations
        id: check-violations
        run: |
          echo "ðŸš¨ Checking for critical violations..."
          
          critical_count=0
          if [ -f "analysis-results/summary.json" ]; then
            critical_count=$(python -c "import json; data=json.load(open('analysis-results/summary.json')); print(data.get('critical_violations', 0))")
          fi
          
          echo "critical_violations=$critical_count" >> $GITHUB_OUTPUT
          
          if [ "$critical_count" -gt "0" ]; then
            echo "âŒ Found $critical_count critical violations"
            exit 1
          else
            echo "âœ… No critical violations found"
          fi
          
      - name: Upload CrashLens Analysis Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: crashlens-analysis-${{ github.run_number }}
          path: |
            analysis-results/
            logs/*.jsonl
          retention-days: 30
          
      - name: Comment PR with CrashLens Results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let reportContent = '## ðŸŽ¯ CrashLens Token Waste Analysis\n\n';
            
            try {
              if (fs.existsSync('analysis-results/summary.json')) {
                const summary = JSON.parse(fs.readFileSync('analysis-results/summary.json', 'utf8'));
                
                reportContent += '### ðŸ“Š Violation Summary\n\n';
                reportContent += `- **Total Violations:** ${summary.total_violations}\n`;
                reportContent += `- **Critical:** ${summary.critical_violations} ðŸ”´\n`;
                reportContent += `- **High:** ${summary.high_violations} ðŸŸ \n`;
                reportContent += `- **Medium:** ${summary.medium_violations} ðŸŸ¡\n`;
                reportContent += `- **Low:** ${summary.low_violations} ðŸ”µ\n\n`;
                
                if (summary.critical_violations > 0) {
                  reportContent += 'ðŸš¨ **Critical violations found!** Please review the analysis results.\n\n';
                } else {
                  reportContent += 'âœ… **No critical violations detected.**\n\n';
                }
              } else {
                reportContent += 'âœ… CrashLens analysis completed successfully.\n\n';
              }
              
              reportContent += 'ðŸ“ **Detailed Results:** Check the [workflow artifacts](' + 
                context.payload.pull_request.html_url.replace('/pull/', '/actions') + 
                ') for complete analysis files.\n\n';
                
              reportContent += '*Analyzed by CrashLens v2.9.1 - Token waste detection for AI applications*';
              
            } catch (error) {
              reportContent += 'âš ï¸ Analysis completed but summary could not be generated. Check workflow logs for details.';
            }
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: reportContent
            });
            
      - name: Set Job Summary
        if: always()
        run: |
          echo "## ðŸŽ¯ CrashLens Token Waste Analysis Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Repository:** ${{ github.repository }}" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**CrashLens Version:** $(crashlens --version | cut -d' ' -f3)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "analysis-results/summary.json" ]; then
            echo "### ðŸ“Š Analysis Results:" >> $GITHUB_STEP_SUMMARY
            python -c "
            import json
            with open('analysis-results/summary.json') as f:
              data = json.load(f)
            print(f'- **Total Violations:** {data[\"total_violations\"]}')
            print(f'- **Critical:** {data[\"critical_violations\"]} ðŸ”´')  
            print(f'- **High:** {data[\"high_violations\"]} ðŸŸ ')
            print(f'- **Medium:** {data[\"medium_violations\"]} ðŸŸ¡')
            print(f'- **Low:** {data[\"low_violations\"]} ðŸ”µ')
            " >> $GITHUB_STEP_SUMMARY
          else
            echo "- âœ… Analysis completed successfully" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“Š **View detailed results in the workflow artifacts above**" >> $GITHUB_STEP_SUMMARY
